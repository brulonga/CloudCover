{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerias necesarias para este modelo \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio \n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "from glob import glob\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import v2\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "from skimage.metrics import mean_squared_error as MSE\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import wandb\n",
    "import matplotlib.animation as animation\n",
    "from PIL import Image\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones de utilidad para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveImage(filename, image):\n",
    "    imageTMP = np.clip(image * 255.0, 0, 255).astype('uint8')\n",
    "    imageio.imwrite(filename, imageTMP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mse(img1, img2):\n",
    "    return torch.mean((img1 - img2) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, images_list):\n",
    "        \n",
    "        self.imgs = sorted(images_list)\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        img_path = self.imgs[idx]\n",
    "\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"No se pudo cargar la imagen en la ruta: {img_path}\")\n",
    "\n",
    "        image = (image / 255.0).astype(np.float32)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        assert image.shape[-1] == 3, \"La imagen no tiene 3 canales.\"\n",
    "\n",
    "        img_tensor = torch.from_numpy(image).permute(2, 0, 1)\n",
    "\n",
    "        return img_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "source": [
    "Creamos el dataloader de train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHc=\"/home/brulon/Documentos/TFG/entrenamiento/5\"    \n",
    "IMGS_PATHc=sorted(glob(os.path.join(PATHc, \"*.jpg\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "batchsize = 4  \n",
    "\n",
    "dataset = MyDataset(IMGS_PATHc)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batchsize, num_workers=4, drop_last=True, shuffle=True)   \n",
    "\n",
    "dataloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La red neuronal: U-net y el definición del modelo \n",
    "\n",
    "Se podría sustituir por otra pero en este caso usamos una simple y util, U-net, localizamos el modelo en la variable D y definimos el optimizador a ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Unet, self).__init__()\n",
    "\n",
    "        # block down 1\n",
    "        self.block1_conv1 = torch.nn.Conv2d( 6, 64, kernel_size=(3,3), padding=(1,1), padding_mode='zeros', stride=1)  #numero de canales es 6 \n",
    "        self.block1_conv2 = torch.nn.Conv2d(64, 64, kernel_size=(3,3), padding=(1,1), padding_mode='zeros', stride=2)\n",
    "        # block down 2\n",
    "        self.block2_conv1 = torch.nn.Conv2d(64, 64, kernel_size=(3,3), padding=(1,1), padding_mode='zeros', stride=1)\n",
    "        self.block2_conv2 = torch.nn.Conv2d(64, 64, kernel_size=(3,3), padding=(1,1), padding_mode='zeros', stride=2)\n",
    "        # block down 3\n",
    "        self.block3_conv1 = torch.nn.Conv2d(64, 64, kernel_size=(3,3), padding=(1,1), padding_mode='zeros', stride=1)\n",
    "        self.block3_conv2 = torch.nn.Conv2d(64, 64, kernel_size=(3,3), padding=(1,1), padding_mode='zeros', stride=1)\n",
    "        self.block3_conv3 = torch.nn.Conv2d(64, 64, kernel_size=(3,3), padding=(1,1), padding_mode='zeros', stride=1)\n",
    "        self.block3_conv4 = torch.nn.Conv2d(64, 64, kernel_size=(3,3), padding=(1,1), padding_mode='zeros', stride=2)\n",
    "        # block up 3\n",
    "        self.block3_up1 = torch.nn.ConvTranspose2d(64, 64, kernel_size=(3,3), padding=(1,1), padding_mode='zeros', stride=2, output_padding=1)\n",
    "        self.block3_up2 = torch.nn.Conv2d(64, 64, kernel_size=(3,3), padding=(1,1), padding_mode='zeros', stride=1)\n",
    "        # block up 2\n",
    "        self.block2_up1 = torch.nn.ConvTranspose2d(64, 64, kernel_size=(3,3), padding=(1,1), padding_mode='zeros', stride=2, output_padding=1)\n",
    "        self.block2_up2 = torch.nn.Conv2d(64, 64, kernel_size=(3,3), padding=(1,1), padding_mode='zeros', stride=1)\n",
    "        # block up 1\n",
    "        self.block1_up1 = torch.nn.ConvTranspose2d(64, 64, kernel_size=(3,3), padding=(1,1), padding_mode='zeros', stride=2, output_padding=1)\n",
    "        self.block1_up2 = torch.nn.Conv2d(64, 64, kernel_size=(3,3), padding=(1,1), padding_mode='zeros', stride=1)\n",
    "        # output\n",
    "        self.conv_output = torch.nn.Conv2d(64, 3, kernel_size=(1,1), padding=(0,0), padding_mode='zeros', stride=1)\n",
    "        #\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x, alpha):\n",
    "\n",
    "        b0 = torch.cat([x, alpha[:,None,None,None].repeat(1, 3, 128, 128)], dim=1)\n",
    "\n",
    "        b1_c1 = self.relu(self.block1_conv1(b0))\n",
    "        b1_c2 = self.relu(self.block1_conv2(b1_c1))\n",
    "\n",
    "        b2_c1 = self.relu(self.block2_conv1(b1_c2))\n",
    "        b2_c2 = self.relu(self.block2_conv2(b2_c1))\n",
    "\n",
    "        b3_c1 = self.relu(self.block3_conv1(b2_c2))\n",
    "        b3_c2 = self.relu(self.block3_conv2(b3_c1))\n",
    "        b3_c3 = self.relu(self.block3_conv3(b3_c2)) + b3_c1\n",
    "        b3_c4 = self.relu(self.block3_conv4(b3_c3))\n",
    "\n",
    "        u2_c1 = self.relu(self.block3_up1(b3_c4)) + b3_c3\n",
    "        u2_c2 = self.relu(self.block3_up2(u2_c1)) + b2_c2\n",
    "\n",
    "        u1_c1 = self.relu(self.block2_up1(u2_c2)) + b1_c2\n",
    "        u1_c2 = self.relu(self.block2_up2(u1_c1))\n",
    "\n",
    "        u0_c1 = self.relu(self.block1_up1(u1_c2)) + b1_c1\n",
    "        u0_c2 = self.relu(self.block1_up2(u0_c1))\n",
    "\n",
    "        output = self.conv_output(u0_c2)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "D = Unet().to('cuda')\n",
    "optimizer_D = torch.optim.Adam(D.parameters(), lr=0.0005)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento y evaluación "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos las listas para las metricas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics= defaultdict(list)\n",
    "train_loss=[]\n",
    "train_mse=[]\n",
    "train_psnr=[]\n",
    "train_ssim=[]\n",
    "\n",
    "eval_loss=[]\n",
    "eval_psnr_final=[]\n",
    "eval_mse=[]\n",
    "eval_mse_final=[]\n",
    "eval_psnr=[]\n",
    "eval_ssim=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def generate_gaussian_noise(tensor, mean=0.0, std=1.0):\n",
    "    \"\"\"\n",
    "    Genera un tensor de ruido gaussiano con las mismas dimensiones que el tensor de entrada.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): El tensor de entrada para tomar sus dimensiones.\n",
    "        mean (float, opcional): Media de la distribución gaussiana. Por defecto es 0.0.\n",
    "        std (float, opcional): Desviación estándar de la distribución gaussiana. Por defecto es 1.0.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Un tensor de ruido gaussiano con las mismas dimensiones que el tensor de entrada.\n",
    "    \"\"\"\n",
    "    return torch.normal(mean=mean, std=std, size=tensor.size())\n",
    "\n",
    "# Ejemplo de uso:\n",
    "# Suponiendo que tienes un tensor de entrada de dimensiones [3, 224, 224]\n",
    "input_tensor = torch.randn(3, 224, 224)  # Un tensor de ejemplo\n",
    "noise_tensor = generate_gaussian_noise(input_tensor, mean=0.0, std=1.0)\n",
    "\n",
    "print(noise_tensor.shape)  # Verifica que las dimensiones coincidan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# training loop\n",
    "for period in range(600):\n",
    "    D.train()\n",
    "    for batch in tqdm(dataloader, \"period \" + str(period)):\n",
    "\n",
    "        # get data      \n",
    "        mnistc = -1 + 2*batch[0].to(\"cuda\")   #normaliza y trasporta a [-1,1] los valors de las imágenes;\n",
    "\n",
    "        \n",
    "        mnisto = generate_gaussian_noise(batch, mean=0.0, std=0.1).to(\"cuda\")   #normaliza y trasporta a [-1,1] los valors de las imágenes;\n",
    "\n",
    "        x_0 = mnisto\n",
    "        x_1 = mnistc            \n",
    "        alpha = torch.rand(batchsize, device=\"cuda\")\n",
    "        x_alpha = (1-alpha[:,None,None,None]) * x_0 + alpha[:,None,None,None] * x_1\n",
    "\n",
    "        #perdida \n",
    "        loss = torch.sum( (D(x_alpha, alpha) - (x_1-x_0))**2 )\n",
    "\n",
    "\n",
    "        #MSE\n",
    "\n",
    "        trainmse = torch.mean( (D(x_alpha, alpha) - (x_1-x_0))**2 )\n",
    "\n",
    "        #PSNR de este mse\n",
    "        trainpsnr = 20 * torch.log10(1. / torch.sqrt(trainmse))\n",
    "\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_D.step()\n",
    "    \n",
    "        train_loss.append(loss.item())\n",
    "        train_mse.append(trainmse.item()) \n",
    "        train_psnr.append(trainpsnr.item())  \n",
    "\n",
    "    torch.save({\n",
    "            'model_state_dict': D.state_dict(),\n",
    "            'optimizer_state_dict': optimizer_D.state_dict(),\n",
    "            }, \"Bruno600_5.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta linea solo hay que ejecutarla en el caso de que se pare el entrenamiento, hay que ponerlo antes del entrenamiento y cambiar el numero de epocas que faltan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_316583/3626855355.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"Pesos_Difusion/Bruno600_4.pt\")\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\"Pesos_Difusion/Bruno600_4.pt\")\n",
    "D.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer_D.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampleo de imágenes de test \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leeemos las fotos desde la carpeta de test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Leer la imagenes con OpenCV, solo sirve para ver el tamaño de la imagen esto\n",
    "fototest = cv2.imread('/home/brulon/Documentos/TFG/CloudCover/Datasets/AllSky/test/0/C002_20190101_1525.jpg')\n",
    "\n",
    "# Convertir de BGR a RGB\n",
    "fototestrgb = cv2.cvtColor(fototest, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Convertir a formato PIL (Pillow), que es compatible con PyTorch\n",
    "fototestpil = Image.fromarray(fototestrgb)\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "# Aplicar la transformación para convertir la imagen en un tensor de PyTorch\n",
    "fototest_tensor = to_tensor(fototestrgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y hacemos un sampleo en 10 pasos para visualizar la imagen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # starting points x_alpha = x_0\n",
    "mnisto = -1 + 2*fototest_tensor.to(\"cuda\")   #normaliza y trasporta a [-1,1] los valors de las imágenes;\n",
    "# #mnisto = torch.nn.functional.interpolate(mnisto, size=(32,32), mode='bilinear', align_corners=False) \n",
    "\n",
    "noise=generate_gaussian_noise(mnisto, mean=0.0, std=0.1).to(\"cuda\")  \n",
    "\n",
    "\n",
    "\n",
    "x_0 = noise\n",
    "x_alpha = x_0.unsqueeze(0) \n",
    "\n",
    "\n",
    "T = 300\n",
    "for t in tqdm(range(T), \"sampling testing loop\"):\n",
    "    \n",
    "    #current alpha value\n",
    "    alpha = t / T * torch.ones(1, device=\"cuda\")\n",
    "\n",
    "    #update \n",
    "    x_alpha = x_alpha + 1/T * D(x_alpha, alpha)\n",
    "    x_alphashow=x_alpha\n",
    "\n",
    "\n",
    "    #create result image\n",
    "    result = np.zeros((1*400, 1*600, 3))         \n",
    "    #tmp =x_alphashow.detach().cpu().clone().permute(1,2,0).numpy()\n",
    "    \n",
    "\n",
    "\n",
    "            \n",
    "    tmp = 0.5+0.5*x_alphashow.detach().cpu().clone().squeeze(0).permute(1,2,0).numpy()\n",
    "    result=tmp\n",
    "    \n",
    "    #tmp = np.swapaxes(tmp, 0, 2)\n",
    "    #tmp = np.swapaxes(tmp, 0, 1)\n",
    "    \n",
    "    #print(tmp.shape)\n",
    "    saveImage('Bruno_'+str(t)+'.png', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnisto = -1 + 2*fototest_tensor.to(\"cuda\")   #normaliza y trasporta a [-1,1] los valors de las imágenes;\n",
    "\n",
    "for i in tqdm(range(9000), 'fotos generadas'):\n",
    "    noise=generate_gaussian_noise(mnisto, mean=0.0, std=0.1).to(\"cuda\")  \n",
    "\n",
    "    x_0 = noise\n",
    "    x_alpha = x_0.unsqueeze(0) \n",
    "\n",
    "\n",
    "    T = 300\n",
    "    for t in tqdm(range(T), \"sampling testing loop\"):\n",
    "        \n",
    "        #current alpha value\n",
    "        alpha = t / T * torch.ones(1, device=\"cuda\")\n",
    "\n",
    "        #update \n",
    "        x_alpha = x_alpha + 1/T * D(x_alpha, alpha)\n",
    "        x_alphashow=x_alpha\n",
    "\n",
    "\n",
    "        #create result image\n",
    "        result = np.zeros((1*400, 1*600, 3))         \n",
    "        #tmp =x_alphashow.detach().cpu().clone().permute(1,2,0).numpy()\n",
    "    \n",
    "                \n",
    "        tmp = 0.5+0.5*x_alphashow.detach().cpu().clone().squeeze(0).permute(1,2,0).numpy()\n",
    "        result=tmp\n",
    "        \n",
    "        #tmp = np.swapaxes(tmp, 0, 2)\n",
    "        #tmp = np.swapaxes(tmp, 0, 1)\n",
    "        \n",
    "        #print(tmp.shape)\n",
    "        if t==299:\n",
    "            saveImage('syntetica5/Clase5Sinte_'+str(i)+'.png', result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_TFG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
